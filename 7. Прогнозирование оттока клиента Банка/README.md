# [Прогнозирование оттока клиента Банка](https://github.com/Urchien/Yandex_Practicum/blob/main/7.%20%D0%9F%D1%80%D0%BE%D0%B3%D0%BD%D0%BE%D0%B7%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5%20%D0%BE%D1%82%D1%82%D0%BE%D0%BA%D0%B0%20%D0%BA%D0%BB%D0%B8%D0%B5%D0%BD%D1%82%D0%B0%20%D0%91%D0%B0%D0%BD%D0%BA%D0%B0/bank_turnover.ipynb)

## Статус проекта - завершен.

## Описание проекта

Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.

## Описание данных

Для исследования получен csv-файл Churn.csv который содержит следующие столбцы:

- RowNumber — индекс строки в данных
- CustomerId — уникальный идентификатор клиента
- Surname — фамилия
- CreditScore — кредитный рейтинг
- Geography — страна проживания
- Gender — пол
- Age — возраст
- Tenure — сколько лет человек является клиентом банка
- Balance — баланс на счёте
- NumOfProducts — количество продуктов банка, используемых клиентом
- HasCrCard — наличие кредитной карты
- IsActiveMember — активность клиента
- EstimatedSalary — предполагаемая зарплата
- Exited — факт ухода клиента— 0

Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)

## Задачи проекта

Постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.

Дополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.

## Примененные инструменты

- Python
- Pandas
- Numpy
- Matplotlib
- Seaborn
- Scikit-learn
- Re
- Imbalance-learn

## Результаты исследования

В этом исследовании мы:
- Загрузили необходимые библиотеки и подготовили данные.
    - Привели к "змеиному" стилю имена столбцов.
    - Удалили ненужные признаки row_number, customer_id и surname.
    - Разобрались с пропусками в признаке tenure и привели его в int.
    - Перекодировали признаки geography и gender в числовые, с помощью One-Hot Encoding.
    - Разделили датасет на 3 части в соотношении 3:1:1 (60% обучающая выборка, 20% валидационная и 20% тестовая).
    - Масштабировали числовые признаки credit_score, age, balance, estimated_salary.
    - Обнаружили в целевом признаке exited достаточно сильный дисбаланс классов - только 20% отражают факт ухода клиента.
- Исследовали модели без учета дисбаланса и обнаружили, что случайный лес в F1-мере показывает лучший результат. А матрицы ошибок указывают на сильный дисбаланс классов.  
- Исследовали модели с учетом дисбаланса:
    - С использованием увеличенной выборки(Upsampling), обнаружили что случайный лес в F1-мере показывает лучший результат. AUC-ROC выше F1- меры.  
    - С использованием уменьшенной выборки(Downsampling), обнаружили что случайный лес в F1-мере показывает лучший результат. AUC-ROC выше F1- меры.
    - С использованием Взвешивания классов: , обнаружили что случайный лес в F1-мере показывает лучший результат. AUC-ROC выше F1- меры.   
- Выяснили, что увеличение и уменьшение выборки немного улучшает модель по сравнению исходной.
- Взвешивание классов дает самый низкий результат.
- AUC-ROC колеблется от 78% до 87%
- По результам всех исследований, самые высокие метрики F1 и AUC-ROC у модели обученой с помощью случайного леса с увеличением выборки. 
- Провели тестирование самой успешной модели.
    - Для этого объединили тестовую и валидационную выборки.
    - Полнота (recall) для тестовой выборки: 0.6736196319018405
    - Точность (precision) для тестовой выборки: 0.5815677966101694
    - F1-мера для тестовой выборки: 0.6242183058555998
    - AUC-ROC для тестовой выборки: 0.8598672843370478

**Удалось достичь F1-меры не менее 0.59**, что было основным заданием проекта.

